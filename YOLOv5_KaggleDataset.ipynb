{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
      "/home/ansh.arora/IIITA_Winter21/YOLOv5-CustomDataset/yolov5\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.2.2 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (1.21.2)\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (4.5.4.60)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (8.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (2.26.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (1.7.3)\n",
      "Requirement already satisfied: torch>=1.7.0 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (1.10.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from -r requirements.txt (line 12)) (0.11.2)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from -r requirements.txt (line 13)) (4.62.3)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from -r requirements.txt (line 16)) (2.7.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from -r requirements.txt (line 20)) (1.3.5)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from -r requirements.txt (line 21)) (0.11.2)\n",
      "Requirement already satisfied: thop in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from -r requirements.txt (line 37)) (0.0.31.post2005241907)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.28.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (21.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.9)\n",
      "Requirement already satisfied: typing_extensions in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (3.10.0.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.3.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.43.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (58.0.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.37.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (2.3.3)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.19.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from pandas>=1.1.4->-r requirements.txt (line 20)) (2021.3)\n",
      "Requirement already satisfied: six in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ansh.arora/tmp/ENTER/envs/yolo/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UG2srFcONNXy"
   },
   "outputs": [],
   "source": [
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9D5SiFoNU7A"
   },
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4ATAtm4NXEd"
   },
   "outputs": [],
   "source": [
    "! cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6KL69jBNkGE"
   },
   "outputs": [],
   "source": [
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POzSf7aYNmzN",
    "outputId": "b43cd0d7-ed7d-4e1e-8744-b519c05a7a6f"
   },
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d awsaf49/bdd100k-dataset --force\n",
    "# !kaggle datasets download -d solesensei/solesensei_bdd100k\n",
    "!kaggle datasets download -d nguyentrongquocdat/object-detection-for-autonomous-vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/ansh.arora/IIITA_Winter21/YOLOv5-CustomDataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv Object\\ Detection Object_Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKdWGxIdNrgh",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !unzip YOLOv5-CustomDataset/object-detection-for-autonomous-vehicles.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLh-THewO7-y"
   },
   "outputs": [],
   "source": [
    "# !rm /content/bdd100k-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9VL-U-SQN8kc",
    "outputId": "3121f33d-1213-4b72-b2ae-6ca9ce344572"
   },
   "outputs": [],
   "source": [
    "%cd /content/Object Detection/image/train\n",
    "!ls | wc -l\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kJFTTfU4QihB"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from IPython.display import Image  # for displaying images\n",
    "import os \n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import xml.etree.ElementTree as ET\n",
    "# from xml.dom import minidom\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edG2N8V0Po9m"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# Function to get the data from JSON Annotation\n",
    "def extract_info_from_json(json_file):\n",
    "    json_file = open(json_file)\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "    image_size = [1280,720,3]\n",
    "    \n",
    "    annotations = []\n",
    "    # Parse the JSON Tree\n",
    "    print(len(data))\n",
    "  \n",
    "    for idx in range(len(data)):\n",
    "      # Initialise the info dict \n",
    "      info_dict = {}\n",
    "      info_dict['bboxes'] = []\n",
    "      \n",
    "      info_dict['filename'] = data[idx]['name']\n",
    "      info_dict['image_size'] = tuple(image_size)\n",
    "  \n",
    "      # if(data[idx]['labels']==None):\n",
    "      #   annotations.append(info_dict)\n",
    "      #   continue\n",
    "      try:\n",
    "        for label in data[idx]['labels']:\n",
    "          bbox={}\n",
    "          bbox[\"class\"] = label[\"category\"]\n",
    "\n",
    "          for coord in label['box2d']:\n",
    "            value = label['box2d'][coord]\n",
    "            if(coord == 'x1'):\n",
    "              coord = 'xmin'\n",
    "            elif(coord == 'x2'):\n",
    "              coord ='xmax'\n",
    "            elif(coord == 'y1'):\n",
    "              coord = 'ymin'\n",
    "            elif(coord == 'y2'):\n",
    "              coord = 'ymax'\n",
    "            bbox[coord] = int(value)\n",
    "\n",
    "          info_dict['bboxes'].append(bbox)\n",
    "      except:\n",
    "        annotations.append(info_dict)\n",
    "        print(data[idx])\n",
    "        \n",
    "      annotations.append(info_dict)\n",
    "    return annotations\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JzMfkkYvP74J"
   },
   "outputs": [],
   "source": [
    "# print(extract_info_from_json('/content/bdd100k/labels/box_track_20/train/0000f77c-62c2a288.json'))\n",
    "# print(extract_info_from_json('/content/Object Detection/label/train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uNUPur6QWZo",
    "outputId": "e4a089af-48c6-4a58-8dd6-7001cefe8e09"
   },
   "outputs": [],
   "source": [
    "!mkdir 'Object_Detection/label/train' \n",
    "!mkdir 'Object_Detection/label/val' \n",
    "!mkdir 'Object_Detection/label/test'\n",
    "!mkdir 'Object_Detection/image/val'\n",
    "!mkdir 'Object_Detection/image/train_new'\n",
    "!mkdir 'Object_Detection/label/train_new' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohxNRiKc6Umu"
   },
   "outputs": [],
   "source": [
    "#  !mkdir /content/bdd100k/labels/train /content/bdd100k/labels/val /content/bdd100k/labels/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ldc8IKt7dyzD"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive._mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iU61l8N8QLQW"
   },
   "outputs": [],
   "source": [
    "# Dictionary that maps class names to IDs\n",
    "class_name_to_id_mapping = {\"pedestrian\":0,\n",
    "                            \"rider\":1,\n",
    "                            \"car\":2,\n",
    "                            \"truck\":3,\n",
    "                            \"bus\":4,\n",
    "                            \"train\":5,\n",
    "                            \"motorcycle\":6,\n",
    "                            \"bicycle\":7,\n",
    "                            \"traffic light\":8,\n",
    "                            \"traffic sign\":9,\n",
    "                            \"trailer\":10,\n",
    "                            \"other person\": 11,\n",
    "                            \"other vehicle\":12}\n",
    "\n",
    "# class_name_to_id_mapping = {\"pedestrian\":4,\n",
    "#                             \"rider\":7,\n",
    "#                             \"car\":3,\n",
    "#                             \"truck\":6,\n",
    "#                             \"bus\":5,\n",
    "#                             \"train\":10,\n",
    "#                             \"motorcycle\":9,\n",
    "#                             \"bicycle\":8,\n",
    "#                             \"traffic light\":1,\n",
    "#                             \"traffic sign\":2,\n",
    "#                             \"trailer\":13,\n",
    "#                             \"other person\": 12,\n",
    "#                             \"other vehicle\":11}\n",
    "\n",
    "\n",
    "# Convert the info dict to the required yolo format and write it to disk\n",
    "def convert_to_yolov5(info_dict,type):\n",
    "    print_buffer = []\n",
    "    # For each bounding box\n",
    "    # if(int(len(info_dict[\"bboxes\"])==0)):\n",
    "    #   save_file_name = os.path.join(\"/content/bdd100k/bdd100k/labels/\"+type, info_dict[\"filename\"].replace(\"jpg\", \"txt\"))\n",
    "    #   print(\"\", file= open(save_file_name, \"w\"))\n",
    "    for b in info_dict[\"bboxes\"]:\n",
    "        try:\n",
    "          class_id = class_name_to_id_mapping[b[\"class\"]]\n",
    "        except KeyError:\n",
    "            print(b)\n",
    "            print(\"Invalid Class. Must be one from \", class_name_to_id_mapping.keys())\n",
    "        \n",
    "        # Transform the bbox co-ordinates as per the format required by YOLO v5\n",
    "        b_center_x = (b[\"xmin\"] + b[\"xmax\"]) / 2 \n",
    "        b_center_y = (b[\"ymin\"] + b[\"ymax\"]) / 2\n",
    "        b_width    = (b[\"xmax\"] - b[\"xmin\"])\n",
    "        b_height   = (b[\"ymax\"] - b[\"ymin\"])\n",
    "        \n",
    "        # Normalise the co-ordinates by the dimensions of the image\n",
    "        image_w, image_h, image_c = info_dict[\"image_size\"]  \n",
    "        b_center_x /= image_w \n",
    "        b_center_y /= image_h \n",
    "        b_width    /= image_w \n",
    "        b_height   /= image_h \n",
    "        \n",
    "        #Write the bbox details to the file \n",
    "        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, b_center_x, b_center_y, b_width, b_height))\n",
    "        \n",
    "    # Name of the file which we have to save \n",
    "    save_file_name = os.path.join(\"Object_Detection/label/\"+type, info_dict[\"filename\"].replace(\"jpg\", \"txt\"))\n",
    "    \n",
    "    # Save the annotation to disk\n",
    "    print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5PLz60AQjNS"
   },
   "outputs": [],
   "source": [
    "# # Get the annotations\n",
    "# # annotations = [os.path.join('/content/bdd100k/labels/box_track_20/train', x) for x in os.listdir('/content/bdd100k/labels/box_track_20/train') if x[-4:] == \"json\"]\n",
    "# annotations.sort()\n",
    "# print(annotations)\n",
    "\n",
    "\n",
    "# # Convert and save the annotations\n",
    "# for ann in tqdm(annotations):\n",
    "#     info_dict = extract_info_from_json(ann)\n",
    "#     for i in info_dict:\n",
    "#       # print(i)\n",
    "#       convert_to_yolov5(i,\"train\")\n",
    "#       # print(\"--------------------\")      \n",
    "# annotations = [os.path.join('/content/bdd100k/labels/box_track_20/train', x) for x in os.listdir('/content/bdd100k/labels/box_track_20/train') if x[-3:] == \"txt\"]\n",
    "# print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3z7_I6BjTkK9"
   },
   "outputs": [],
   "source": [
    "# Assuming you're in the data folder\n",
    "# !cat /content/bdd100k/bdd100k/labels/det_v2_train_release.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZ77_i0IKqlJ",
    "outputId": "d6402620-0a24-495e-aa10-b5240b36aa7f"
   },
   "outputs": [],
   "source": [
    "#train annotations\n",
    "info_dict = extract_info_from_json('Object_Detection/label/train.json')\n",
    "# print(info_dict)\n",
    "for i in info_dict:\n",
    "    convert_to_yolov5(i,\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2JkEpXcQ110",
    "outputId": "75605405-4e0f-493f-fb5b-e7d82276b487"
   },
   "outputs": [],
   "source": [
    "#train annotations\n",
    "info_dict = extract_info_from_json('Object_Detection/label/test.json')\n",
    "# print(info_dict)\n",
    "for i in info_dict:\n",
    "    convert_to_yolov5(i,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEDm1cklRMzc"
   },
   "outputs": [],
   "source": [
    "# annotations = [os.path.join('/content/bdd100k/bdd100k/labels/train', x) for x in os.listdir('/content/bdd100k/bdd100k/labels/train') if x[-3:] == \"txt\"]\n",
    "# print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arvVKzQKCjEc"
   },
   "outputs": [],
   "source": [
    "# !rm -rf /content/Object Detection/label/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksJvuHaBCZgE"
   },
   "outputs": [],
   "source": [
    "# %cd /content/Object Detection/label/\n",
    "# !rm -rf val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K30C2-m_SBOP",
    "outputId": "f4e96df8-1213-486f-a13d-9b1919075f86"
   },
   "outputs": [],
   "source": [
    "%cd /content/bdd100k/bdd100k/images/100k/train\n",
    "!ls | wc -l\n",
    "%cd /content/bdd100k/bdd100k/labels/train\n",
    "!ls | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Si6pJmtod0my",
    "outputId": "1904de06-4b66-4e37-a4af-c0d26a4cb03c"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/drive/MyDrive/bdd100k_det_20_labels_trainval.zip -d /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBlg4dFzeCea",
    "outputId": "d983422c-de93-4e80-98ef-44733d5a7981"
   },
   "outputs": [],
   "source": [
    "# #train annotations\n",
    "# info_dict = extract_info_from_json('/content/bdd100k/bdd100k/labels/det_v2_val_release.json')\n",
    "# # print(info_dict)\n",
    "# for i in info_dict:\n",
    "#     convert_to_yolov5(i,\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_FV2oLQeJLw",
    "outputId": "864cf7f3-0aed-408a-9173-0e11a9c7cda9"
   },
   "outputs": [],
   "source": [
    "%cd /content/Object Detection/label/val\n",
    "!ls | wc -l\n",
    "%cd /content/bdd100k/bdd100k/labels/val\n",
    "!ls | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6GMGRuWYL18U"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MUZUXyH1DBeF"
   },
   "outputs": [],
   "source": [
    "annotations = [os.path.join('Object_Detection/label/train', x) for x in os.listdir('Object_Detection/label/train') if x[-3:] == \"txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b9rSagmmDzBO"
   },
   "outputs": [],
   "source": [
    "images = [os.path.join('Object_Detection/image/train', x) for x in os.listdir('Object_Detection/image/train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vye75OQ5EH5_",
    "outputId": "513fcd36-2712-45bd-f507-320727af8a5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# import required module\n",
    "# import os\n",
    "# assign directory\n",
    "directory = 'Object_Detection/image/train'\n",
    "labels = 'Object_Detection/label/train/'\n",
    "# iterate over files in\n",
    "# that directory\n",
    "ans=0\n",
    "for filename in os.listdir(directory):\n",
    "  if(os.path.exists(labels+filename.replace(\"jpg\", \"txt\"))==False):\n",
    "    print(filename)\n",
    "    os.remove(directory+'/'+filename)\n",
    "    ans+=1\n",
    "print(ans)\n",
    "  # break\n",
    "# for filename in os.listdir(directory):\n",
    "#   print(filename)\n",
    "# \tf = os.path.join(directory, filename)\n",
    "# \t# checking if it is a file\n",
    "# \t# if os.path.isfile(f):\n",
    "#   #    print(filename)  \n",
    "#   break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gP9Nw21_Ll3_",
    "outputId": "9a98f933-f1ef-4ca0-b70a-9df52749a6c9"
   },
   "outputs": [],
   "source": [
    "%cd Object_Detection/image/train\n",
    "!ls | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ansh.arora/IIITA_Winter21/YOLOv5-CustomDataset\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ansh.arora/IIITA_Winter21/YOLOv5-CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "frxEbnXxeyXl",
    "outputId": "237ddb7f-4b0a-4eb4-8a86-da91affd4bf1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_name_to_id_mapping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1320296/2525292391.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# random.seed(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclass_id_to_name_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name_to_id_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name_to_id_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_bounding_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_name_to_id_mapping' is not defined"
     ]
    }
   ],
   "source": [
    "# random.seed(0)\n",
    "\n",
    "class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))\n",
    "\n",
    "def plot_bounding_box(image, annotation_list):\n",
    "    annotations = np.array(annotation_list)\n",
    "    w, h = image.size\n",
    "    \n",
    "    plotted_image = ImageDraw.Draw(image)\n",
    "\n",
    "    transformed_annotations = np.copy(annotations)\n",
    "    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n",
    "    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h \n",
    "    \n",
    "    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n",
    "    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n",
    "    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n",
    "    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n",
    "    print(transformed_annotations)\n",
    "\n",
    "    for ann in transformed_annotations:\n",
    "        obj_cls, x0, y0, x1, y1 = ann\n",
    "        plotted_image.rectangle(((x0,y0), (x1,y1)),outline =\"red\")\n",
    "        \n",
    "        plotted_image.text((x0, y0 - 10), class_id_to_name_mapping[(int(obj_cls))])\n",
    "    \n",
    "    plt.imshow(np.array(image))\n",
    "    plt.show()\n",
    "\n",
    "# Get any random annotation file \n",
    "annotation_file = random.choice(annotations)\n",
    "# annotation_file = \"/content/bdd100k/labels/box_track_20/train/0000f77c-62c2a288-0000020.txt\"\n",
    "# print(annotation_file.index(\"0000f77c-62c2a288-0000020\"))\n",
    "# print(annotation_file.index(\"-0000020\"))\n",
    "# print(annotation_file.index(\".txt\"))\n",
    "file_name = annotation_file[29:59]\n",
    "print(annotation_file)\n",
    "print(file_name)\n",
    "with open(annotation_file, \"r\") as file:\n",
    "    annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "    annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "    annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "    \n",
    "\n",
    "#Get the corresponding image file\n",
    "image_file = annotation_file.replace(\"label/\", \"image/\").replace(\"txt\", \"jpg\")\n",
    "print(image_file)\n",
    "# image_file = \"/content/bdd100k/images/track/train/0000f77c-62c2a288/0000f77c-62c2a288-0000020.jpg\"\n",
    "assert os.path.exists(image_file)\n",
    "\n",
    "#Load the image\n",
    "image = Image.open(image_file)\n",
    "\n",
    "#Plot the Bounding Box\n",
    "plot_bounding_box(image, annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kcsa0AGsEHrf"
   },
   "outputs": [],
   "source": [
    "images.sort()\n",
    "annotations.sort()\n",
    "# Split the dataset into train-valid-test splits \n",
    "train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RKDoAwg2E5Nn"
   },
   "outputs": [],
   "source": [
    "#Utility function to move images \n",
    "def move_files_to_folder(list_of_files, destination_folder):\n",
    "    for f in list_of_files:\n",
    "        try:\n",
    "            shutil.move(f, destination_folder)\n",
    "        except:\n",
    "            print(f)\n",
    "            assert False\n",
    "\n",
    "# Move the splits into their folders\n",
    "move_files_to_folder(train_images, 'Object_Detection/image/train_new')\n",
    "move_files_to_folder(val_images, 'Object_Detection/image/val')\n",
    "# move_files_to_folder(test_images, 'images/test/')\n",
    "# move_files_to_folder(train_annotations, 'annotations/train/')\n",
    "# move_files_to_folder(val_annotations, 'annotations/val/')\n",
    "# move_files_to_folder(test_annotations, 'annotations/test/')\n",
    "move_files_to_folder(train_annotations, 'Object_Detection/label/train_new')\n",
    "move_files_to_folder(val_annotations, 'Object_Detection/label/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spwaUyaLMS5i",
    "outputId": "17dda3e9-1794-4baa-9339-f2b0bd0a7204"
   },
   "outputs": [],
   "source": [
    "# !mv /content/Object_Detection/images/train_new /content/Object_Detection/images/train\n",
    "# !mv /content/Object_Detection/labels/train_new /content/Object_Detection/labels/train\n",
    "!mv Object_Detection/image Object_Detection/images\n",
    "!mv Object_Detection/label Object_Detection/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rCaJ1zW7QnEI",
    "outputId": "668b4790-abe9-47f4-912b-1ea1f1c6b7ee"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive._mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RaEOQczIM6NJ",
    "outputId": "09e4f022-94e9-4c79-bb58-fc9be4e75b40"
   },
   "outputs": [],
   "source": [
    "!zip -r '/content/gdrive/MyDrive/IIITA_Winter/bdd100k.zip' /content/Object_Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zOtqJTLT8RL"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/gdrive/MyDrive/IIITA_Winter/bdd100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VmIovH5Q0Sq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "YOLOv5-KaggleDataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
